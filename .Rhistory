source('~/Desktop/Projects/EdTechGen/Rscripts/punctuate.R')
# 5. Punctuate transcriptions and save them
reticulate::use_python("/home/sofianembarki/anaconda2/bin/python")
quit()
q()
q!
# 7. Descriptive analysis on words from speech and word cloud
reticulate:::use_virtualenv('edtech_env', required = T)
reticulate:::initialize_python()
dom_txt <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged)
transcriptions_eng <- transcriptions[nom_eng]
nom_eng <- c("artarchitecture-johannes-vermeer", "history-consumerism", "literature-voltaire", "r_oop_datacamp", "sociology-alexis-de-tocqueville")
transcriptions_eng <- transcriptions[nom_eng]
View(transcriptions)
# 5. Punctuate transcriptions and save them
load('output/transcriptions_eng.Rdata')
load("output/videos_object.Rdata")
# 7. Descriptive analysis on words from speech and word cloud
reticulate:::use_virtualenv('edtech_env', required = T)
reticulate:::initialize_python()
# ----------- Load python module
reticulate:::source_python(file = "Pyscripts/video_to_speech.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_grams.py")
reticulate:::source_python(file = "Pyscripts/wiki_grab.py")
reticulate:::source_python(file = "Pyscripts/summarizer.py")
# ----------- Load R functions
source("Rscripts/upload_to_gcs.R")
source("Rscripts/audio_to_text.R")
source("Rscripts/punctuate.R")
source("Rscripts/meaning_words.R")
source("Rscripts/word_to_cloud.R")
source("Rscripts/utilities/functions/merged_translation.R")
source("Rscripts/utilities/functions/merged_transcription.R")
dom_txt <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged)
dom_txt
context_information <- meaning_words(cleaned_word = dom_txt) # {plot, data.frame}
View(context_information)
context_information$words_plot
context_information$ngrams_plot
word_to_cloud(text) # {wordcloud plot}
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged)
context_information <- meaning_words(cleaned_word = text)
word_to_cloud(text) # {wordcloud plot}
videos_object$`artarchitecture-johannes-vermeer`$classifyText
videos_object$`artarchitecture-johannes-vermeer`$wikipedia
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged)
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged
videos_object$`artarchitecture-johannes-vermeer`$documentSentiment
videos_object$`artarchitecture-johannes-vermeer`$documentSentiment
videos_object$`artarchitecture-johannes-vermeer`$sentiment
videos_object$`artarchitecture-johannes-vermeer`$timings
videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
text
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
text
context_information <- meaning_words(cleaned_word = text)
context_information
cleaned_words <- text
cleaned_words
context_information <- meaning_words(cleaned_word = cleaned_words)
context_information
text
source("Rscripts/meaning_words.R")
context_information <- meaning_words(cleaned_word = cleaned_words)
context_information
source('~/Desktop/Projects/EdTechGen/Rscripts/meaning_words.R')
context_information <- meaning_words(cleaned_word = cleaned_words)
context_information
text <- word_to_work(videos_object$`artarchitecture-johannes-vermeer`$trancriptions_merged, "en")
context_information <- meaning_words(cleaned_word = cleaned_words)
context_information
text <- word_to_work(videos_object$`history-consumerism`$trancriptions_merged, "en")
context_information <- meaning_words(cleaned_word = cleaned_words)
context_information$words_plot
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
source('~/Desktop/Projects/EdTechGen/Rscripts/meaning_words.R')
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
word_to_cloud(text) # {wordcloud plot}
text <- word_to_work(videos_object$`literature-voltaire`, "en")
text <- word_to_work(videos_object$`literature-voltaire`$trancriptions_merged, "en")
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
word_to_cloud(text) # {wordcloud plot}
text <- word_to_work(videos_object$r_oop_datacamp$trancriptions_merged, "en")
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
text <- word_to_work(videos_object$`sociology-alexis-de-tocqueville`$trancriptions_merged, "en")
context_information <- meaning_words(cleaned_word = text)
context_information$words_plot
context_information$ngrams_plot
word_to_cloud(text) # {wordcloud plot}
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
detect_tendacy(videos_object = videos_object)
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
detect_tendacy(videos_object = videos_object)
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
detect_tendacy(videos_object = videos_object)
videos_object <- detect_tendacy(videos_object = videos_object)
videos_object$`artarchitecture-johannes-vermeer`$context_description$ngrams_plot
videos_object$`literature-voltaire`$context_description$ngrams_plot
source('~/Desktop/Projects/EdTechGen/Rscripts/detect_tendancy.R')
videos_object <- detect_tendacy(videos_object = videos_object)
videos_object$`literature-voltaire`$context_description$words_df
videos_object$`literature-voltaire`$context_description$words_plot
videos_object$`literature-voltaire`$wikipedia
a <- videos_object$`literature-voltaire`$wikipedia
View(a)
a
a$wikipedia_url
# 7. Descriptive analysis on words from speech and word cloud
reticulate:::use_virtualenv('edtech_env', required = T) ; reticulate:::initialize_python()
load(file = "output/videos_object.Rdata")
# ----------- Load python module
reticulate:::source_python(file = "Pyscripts/video_to_speech.py")
reticulate:::source_python(file = "Pyscripts/word_to_work.py")
reticulate:::source_python(file = "Pyscripts/word_grams.py")
reticulate:::source_python(file = "Pyscripts/wiki_grab.py")
reticulate:::source_python(file = "Pyscripts/summarizer.py")
# ----------- Load R functions
source("Rscripts/upload_to_gcs.R")
source("Rscripts/audio_to_text.R")
source("Rscripts/punctuate.R")
source("Rscripts/meaning_words.R")
source("Rscripts/word_to_cloud.R")
source("Rscripts/utilities/functions/merged_transcription.R")
source("Rscripts/nlp_processing.R")
source("Rscripts/detect_tendancy.R")
videos_object <- detect_tendacy(videos_object = videos_object)
videos_object$`sociology-alexis-de-tocqueville`$timings
df <- videos_object$`sociology-alexis-de-tocqueville`$timings
View(df)
df <- videos_object$`sociology-alexis-de-tocqueville`$trancriptions_merged
videos_object$`sociology-alexis-de-tocqueville`$trancriptions_merged
videos_object$`sociology-alexis-de-tocqueville`$text
videos_object$`sociology-alexis-de-tocqueville`$entities
df <- videos_object$`sociology-alexis-de-tocqueville`$entities
View(df)
df <- videos_object$`sociology-alexis-de-tocqueville`$wikipedia
df <- videos_object$`sociology-alexis-de-tocqueville`$sentiment
df
df <- videos_object$`sociology-alexis-de-tocqueville`$classifyText
df
df <- videos_object$`sociology-alexis-de-tocqueville`$documentSentiment
df
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description$words_df
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description$words_plot
df
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description$ngrams_plot
df
videos_object$`literature-voltaire`$text
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description$words_df
View(df)
df <- videos_object$`sociology-alexis-de-tocqueville`$context_description$ngrams_df
library("rvest")
url <- "http://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population"
population <- url %>%
html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/table[1]') %>%
html_table()
population
population[[1]]
install.packages("rvest")
install.packages("rvest")
url <- "http://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population"
population <- url %>%
html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/table[1]') %>%
html_table()
population <- population[[1]]
url <- "http://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population"
population <- url %>%
read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/table[1]') %>%
html_table()
population <- population[[1]]
population
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
library(WikipediR)
library(RCurl)
library(XML)
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
op_editors_page <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
top_editors_table <- readHTMLTable(top_editors_page)
top_editors_page <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
top_editors_table <- readHTMLTable(top_editors_page)
library(WikipediR)
library(RCurl)
library(XML)
top_editors_page <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
top_editors_table <- readHTMLTable(top_editors_page)
top_editors_table <- getURLContent(top_editors_page)
top_editors_table
allPages <- lapply(urls, function(x) top_editors_table[[1]])
allPages <- lapply(top_editors_page, function(x) top_editors_table[[1]])
allPages
allPages[[1]]
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
library(rvest)
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
url <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
source('~/Desktop/Projects/EdTechGen/Rscripts/scrapers/wiki_scraper.R')
temp <- url %>%
html %>%
html_nodes("table")
temp <- url %>%
read_html %>%
html_nodes("table")
temps
temp
html_table(temp[1])
html_table(temp[1], fill = T)
html_table(temp[2], fill = T)
temp <- url %>%
read_html %>%
html_nodes("content")
temps
temp <- url %>%
read_html %>%
html_nodes("mw-body")
temp
url <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
temp <- url %>%
read_html %>%
html_nodes("mw-body")
temp
temp <- url %>%
read_html %>%
html_nodes("bodyContent")
temp <- url %>%
read_html %>%
html_nodes("mw-body-content")
temp
url <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
temp <- url %>%
read_html %>%
html_nodes("mw-body-content")
temp
temp[[1]]
temp <- url %>%
read_html %>%
html_nodes("a")
temp
temp <- url %>%
read_html %>%
html_nodes("h1")
temp
temp[[1]]
temp <- url %>%
read_html %>%
html_nodes("h1") %>%
html_text()
temp
title <-
temp <- url %>%
read_html %>%
html_nodes(xpath = "h1") %>%
html_text()
title <-
temp <- url %>%
read_html %>%
html_nodes(x = "h1") %>%
html_text()
title <-
temp <- url %>%
read_html %>%
html_nodes("h1") %>%
html_text()
title <-
temp <- url %>%
read_html %>%
html_nodes(x = "h1") %>%
html_text()
texte <- url %>% read_html %>% html_nodes(page, "div#content") %>% html_text()
url <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
title <-
url %>%
read_html %>%
html_nodes("h1") %>%
html_text()
texte <- url %>% read_html %>% html_nodes(page, "div#content") %>% html_text()
texte <- url %>% read_html %>% html_nodes(page, "toctitle") %>% html_text()
texte <- url %>% read_html %>% html_nodes("toctitle") %>% html_text()
texte <- url %>% read_html %>% html_nodes("div#content") %>% html_text()
text()
texte
texte <- url %>% read_html %>% html_nodes("p") %>% html_text()
texte
texte <- url %>% read_html %>% html_nodes("div#toctitle") %>% html_text()
texte <- url %>% read_html %>% html_nodes("div#ltr") %>% html_text()
texte <- url %>% read_html %>% html_nodes("[class='toctitle']") %>% html_text()
texte <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text()
texte
texte <- url %>% read_html %>% html_nodes("[class='toc']")
texte
%>% html_text()
texte <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text()
table_contents <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text()
strsplit(table_contents, split = "\n")
table_contents <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text() %>% strsplit(table_contents, split = "\n")
wiki_content <- list()
wiki_content <- list()
wiki_content <- list(title, resume)
wiki_content <- list(title = NA, resume = NA)
wiki_content$title <- title
wiki_content$resume <- table_contents
wiki_content
wiki_content$resume[[1]]
table_contents <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text() %>% strsplit(table_contents, split = "\n")
table_contents <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text() %>% strsplit(table_contents, split = "\n") %>% unlist()
url <- "https://fr.wikipedia.org/wiki/%C3%89ducation"
wiki_content <- list(title = NA, table_contents = NA)
title <-
url %>%
read_html %>%
html_nodes("h1") %>%
html_text()
table_contents <- url %>% read_html %>% html_nodes("[class='toc']") %>% html_text() %>% strsplit(table_contents, split = "\n") %>% unlist()
wiki_content$title <- title
wiki_content$table_contents <- table_contents
wiki_content$table_contents
x <- url %>% html_nodes("h2") %>% html_text()
x <- url %>% read_html %>% html_nodes("h2") %>% html_text
x
x <- url %>% read_html %>% html_nodes("h2")
x
x]
x[2]
x[2] %>% html_text
x[2][[1]]
x[2][[2]]
x[2][1]
x[2][[1]]
x[2][[1]][3]
x[2][[1]][2]
x[2][[1]][[1]]
x[2][[1]]
x[2][[1]]$doc
x[2][[1]]$node
table_contents
h3 <- url %>% read_html %>% html_nodes("h2")
h3
h3 <- url %>% read_html %>% html_nodes("h3")
h3
